<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>关于PGGAN PyTorch代码中的一些问题 | HapiBlog</title><meta name="description" content="关于PGGAN PyTorch代码中的一些问题"><meta name="keywords" content="PyTorch,GANs"><meta name="author" content="wwq"><meta name="copyright" content="wwq"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="关于PGGAN PyTorch代码中的一些问题"><meta name="twitter:description" content="关于PGGAN PyTorch代码中的一些问题"><meta name="twitter:image" content="https://i.loli.net/2019/11/13/HbTRirt8nyfpNWF.jpg"><meta property="og:type" content="article"><meta property="og:title" content="关于PGGAN PyTorch代码中的一些问题"><meta property="og:url" content="wwq66.github.io/2019/11/26/pytorchRecord/"><meta property="og:site_name" content="HapiBlog"><meta property="og:description" content="关于PGGAN PyTorch代码中的一些问题"><meta property="og:image" content="https://i.loli.net/2019/11/13/HbTRirt8nyfpNWF.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="wwq66.github.io/2019/11/26/pytorchRecord/"><link rel="prev" title="ganloss" href="/wwq66.github.io/2019/12/05/ganloss/"><link rel="next" title="【PGGAN】PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION" href="/wwq66.github.io/2019/11/25/pggan/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  copyright: undefined,
  copy_copyright_js: false,
  ClickShowText: {"text":"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善","fontSize":"15px"},
  medium_zoom: 'false',
  Snackbar: undefined
  
}</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div id="header"> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">HapiBlog</a></span><i class="fa fa-bars fa-fw toggle-menu pull_right close" aria-hidden="true"></i><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></span><span class="pull_right" id="search_button"></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lazyload avatar_img" src="https://i.loli.net/2019/11/13/JOfPYqLG7gpkbcv.jpg" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">7</div></a></div></div><div class="mobile_data_item is_center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">5</div></a></div></div><div class="mobile_data_item is_center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">2</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#He-initialization"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">He initialization</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#named-children-和named-modules"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">named_children()和named_modules()</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#pixel-wise-normalization-和local-response-normalization-LRN"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">pixel-wise normalization 和local response normalization(LRN)</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#minibatch-standard-deviation"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">minibatch standard deviation</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#有针对性地给样本加噪声"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text">有针对性地给样本加噪声</span></a></li></ol></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#He-initialization"><span class="toc-number">1.</span> <span class="toc-text">He initialization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#named-children-和named-modules"><span class="toc-number">2.</span> <span class="toc-text">named_children()和named_modules()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pixel-wise-normalization-和local-response-normalization-LRN"><span class="toc-number">3.</span> <span class="toc-text">pixel-wise normalization 和local response normalization(LRN)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#minibatch-standard-deviation"><span class="toc-number">4.</span> <span class="toc-text">minibatch standard deviation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#有针对性地给样本加噪声"><span class="toc-number">5.</span> <span class="toc-text">有针对性地给样本加噪声</span></a></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://i.loli.net/2019/11/13/HbTRirt8nyfpNWF.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">关于PGGAN PyTorch代码中的一些问题</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2019-11-26<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2019-12-07</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Paper-Reading/">Paper Reading</a></span><div class="post-meta-wordcount"><i class="fa fa-eye post-meta__icon" aria-hidden="true">       </i><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h2 id="He-initialization"><a href="#He-initialization" class="headerlink" title="He initialization"></a>He initialization</h2><p>关于权值的初始化方式，pggan中采用的是kaiming初始化，代码如下</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kaiming_normal_</span><span class="params">(tensor, a=<span class="number">0</span>, mode=<span class="string">'fan_in'</span>, nonlinearity=<span class="string">'leaky_relu'</span>)</span>:</span></span><br><span class="line">    <span class="string">r"""Fills the input `Tensor` with values according to the method</span></span><br><span class="line"><span class="string">    described in "Delving deep into rectifiers: Surpassing human-level</span></span><br><span class="line"><span class="string">    performance on ImageNet classification" - He, K. et al. (2015), using a</span></span><br><span class="line"><span class="string">    normal distribution. The resulting tensor will have values sampled from</span></span><br><span class="line"><span class="string">    :math:`\mathcal&#123;N&#125;(0, \text&#123;std&#125;)` where</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \text&#123;std&#125; = \sqrt&#123;\frac&#123;2&#125;&#123;(1 + a^2) \times \text&#123;fan_in&#125;&#125;&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Also known as He initialization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        tensor: an n-dimensional `torch.Tensor`</span></span><br><span class="line"><span class="string">        a: the negative slope of the rectifier used after this layer (0 for ReLU</span></span><br><span class="line"><span class="string">            by default)</span></span><br><span class="line"><span class="string">        mode: either 'fan_in' (default) or 'fan_out'. Choosing `fan_in`</span></span><br><span class="line"><span class="string">            preserves the magnitude of the variance of the weights in the</span></span><br><span class="line"><span class="string">            forward pass. Choosing `fan_out` preserves the magnitudes in the</span></span><br><span class="line"><span class="string">            backwards pass.</span></span><br><span class="line"><span class="string">        nonlinearity: the non-linear function (`nn.functional` name),</span></span><br><span class="line"><span class="string">            recommended to use only with 'relu' or 'leaky_relu' (default).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples:</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; w = torch.empty(3, 5)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; nn.init.kaiming_normal_(w, mode='fan_out', nonlinearity='relu')</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    fan = _calculate_correct_fan(tensor, mode)</span><br><span class="line">    gain = calculate_gain(nonlinearity, a)</span><br><span class="line">    std = gain / math.sqrt(fan)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">return</span> tensor.normal_(<span class="number">0</span>, std)</span><br></pre></td></tr></table></figure>
<p>可以看到kaiming初始化是将权值按正态分布$N(0,std)$初始化。标准差的计算公式为$std = \frac{gain}{\sqrt{fan}}$。即需要知道gain和fan的值。fan的求法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calculate_correct_fan</span><span class="params">(tensor, mode)</span>:</span></span><br><span class="line">    mode = mode.lower()</span><br><span class="line">    valid_modes = [<span class="string">'fan_in'</span>, <span class="string">'fan_out'</span>]</span><br><span class="line">    <span class="keyword">if</span> mode <span class="keyword">not</span> <span class="keyword">in</span> valid_modes:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"Mode &#123;&#125; not supported, please use one of &#123;&#125;"</span>.format(mode, valid_modes))</span><br><span class="line"></span><br><span class="line">    fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor)</span><br><span class="line">    <span class="keyword">return</span> fan_in <span class="keyword">if</span> mode == <span class="string">'fan_in'</span> <span class="keyword">else</span> fan_out</span><br></pre></td></tr></table></figure>
<p>其中mode为“ fan_in”表示保留前向传递中权重方差的大小。 mode为“ fan_out”会保留反向传递的幅度。fan_in和fan_out的求法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calculate_fan_in_and_fan_out</span><span class="params">(tensor)</span>:</span></span><br><span class="line">    dimensions = tensor.ndimension()</span><br><span class="line">    <span class="keyword">if</span> dimensions &lt; <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"Fan in and fan out can not be computed for tensor with less than 2 dimensions"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> dimensions == <span class="number">2</span>:  <span class="comment"># Linear</span></span><br><span class="line">        fan_in = tensor.size(<span class="number">1</span>)</span><br><span class="line">        fan_out = tensor.size(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        num_input_fmaps = tensor.size(<span class="number">1</span>)</span><br><span class="line">        num_output_fmaps = tensor.size(<span class="number">0</span>)</span><br><span class="line">        receptive_field_size = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> tensor.dim() &gt; <span class="number">2</span>:</span><br><span class="line">            receptive_field_size = tensor[<span class="number">0</span>][<span class="number">0</span>].numel()	<span class="comment"># 向量中元素总个数</span></span><br><span class="line">        fan_in = num_input_fmaps * receptive_field_size</span><br><span class="line">        fan_out = num_output_fmaps * receptive_field_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fan_in, fan_out</span><br></pre></td></tr></table></figure>
<p>dimensions为tensor的shape，如[512,512,4,4]。<br>gain的求法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_gain</span><span class="params">(nonlinearity, param=None)</span>:</span></span><br><span class="line">    <span class="string">r"""Return the recommended gain value for the given nonlinearity function.</span></span><br><span class="line"><span class="string">    The values are as follows:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    ================= ====================================================</span></span><br><span class="line"><span class="string">    nonlinearity      gain</span></span><br><span class="line"><span class="string">    ================= ====================================================</span></span><br><span class="line"><span class="string">    Linear / Identity :math:`1`</span></span><br><span class="line"><span class="string">    Conv&#123;1,2,3&#125;D      :math:`1`</span></span><br><span class="line"><span class="string">    Sigmoid           :math:`1`</span></span><br><span class="line"><span class="string">    Tanh              :math:`\frac&#123;5&#125;&#123;3&#125;`</span></span><br><span class="line"><span class="string">    ReLU              :math:`\sqrt&#123;2&#125;`</span></span><br><span class="line"><span class="string">    Leaky Relu        :math:`\sqrt&#123;\frac&#123;2&#125;&#123;1 + \text&#123;negative_slope&#125;^2&#125;&#125;`</span></span><br><span class="line"><span class="string">    ================= ====================================================</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        nonlinearity: the non-linear function (`nn.functional` name)</span></span><br><span class="line"><span class="string">        param: optional parameter for the non-linear function</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples:</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; gain = nn.init.calculate_gain('leaky_relu')</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    linear_fns = [<span class="string">'linear'</span>, <span class="string">'conv1d'</span>, <span class="string">'conv2d'</span>, <span class="string">'conv3d'</span>, <span class="string">'conv_transpose1d'</span>, <span class="string">'conv_transpose2d'</span>, <span class="string">'conv_transpose3d'</span>]</span><br><span class="line">    <span class="keyword">if</span> nonlinearity <span class="keyword">in</span> linear_fns <span class="keyword">or</span> nonlinearity == <span class="string">'sigmoid'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> nonlinearity == <span class="string">'tanh'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">5.0</span> / <span class="number">3</span></span><br><span class="line">    <span class="keyword">elif</span> nonlinearity == <span class="string">'relu'</span>:</span><br><span class="line">        <span class="keyword">return</span> math.sqrt(<span class="number">2.0</span>)</span><br><span class="line">    <span class="keyword">elif</span> nonlinearity == <span class="string">'leaky_relu'</span>:</span><br><span class="line">        <span class="keyword">if</span> param <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            negative_slope = <span class="number">0.01</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="keyword">not</span> isinstance(param, bool) <span class="keyword">and</span> isinstance(param, int) <span class="keyword">or</span> isinstance(param, float):</span><br><span class="line">            <span class="comment"># True/False are instances of int, hence check above</span></span><br><span class="line">            negative_slope = param</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"negative_slope &#123;&#125; not a valid number"</span>.format(param))</span><br><span class="line">        <span class="keyword">return</span> math.sqrt(<span class="number">2.0</span> / (<span class="number">1</span> + negative_slope ** <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"Unsupported nonlinearity &#123;&#125;"</span>.format(nonlinearity))</span><br></pre></td></tr></table></figure>
<p>可以看到在nonlinearity为Leaky ReLU时，std的值为$std = \sqrt{\frac{2}{(1+a^2) \times fan_{in}}}$</p>
<h2 id="named-children-和named-modules"><a href="#named-children-和named-modules" class="headerlink" title="named_children()和named_modules()"></a>named_children()和named_modules()</h2><p><strong>named_children()</strong><br>Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself.<br>返回子模块的迭代器，同时产生模块名称以及模块本身。<br><strong>named_modules()</strong><br>Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself.<br>返回网络中所有模块的迭代器，同时产生模块的名称以及模块本身。<br>引用一个网上的例子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestModule</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(TestModule,self).__init__()</span><br><span class="line">        self.layer1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">16</span>,<span class="number">32</span>,<span class="number">3</span>,<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.layer2 = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">32</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line"> </span><br><span class="line">model = TestModule()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> name, module <span class="keyword">in</span> model.named_children():</span><br><span class="line">    print(<span class="string">'children module:'</span>, name)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> name, module <span class="keyword">in</span> model.named_modules():</span><br><span class="line">    print(<span class="string">'modules:'</span>, name)</span><br></pre></td></tr></table></figure>
<p>结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">children module: layer1</span><br><span class="line">children module: layer2</span><br><span class="line">modules: </span><br><span class="line">modules: layer1</span><br><span class="line">modules: layer1<span class="number">.0</span></span><br><span class="line">modules: layer1<span class="number">.1</span></span><br><span class="line">modules: layer2</span><br><span class="line">modules: layer2<span class="number">.0</span></span><br></pre></td></tr></table></figure>

<h2 id="pixel-wise-normalization-和local-response-normalization-LRN"><a href="#pixel-wise-normalization-和local-response-normalization-LRN" class="headerlink" title="pixel-wise normalization 和local response normalization(LRN)"></a>pixel-wise normalization 和local response normalization(LRN)</h2><p>LRN用来进行局部对比度增强，以便使局部特征在下一层表述。公式如下：<br>$$b_{xy}^i = \frac{a_{xy}^i}{[k + \alpha\sum_{j=max(0,i-\frac{n}{2})}^{min(N-1,i+\frac{n}{2})}(a_{xy}^j)^2]^\beta}$$<br>其中$a$为卷积层后的输出，大小为$[N,H,W,C]$，$a_{xy}^i$表示在这个输出结构中的一个位置$[a,b,c,d]$，即第$a$张图的第$d$个通道的高度为$b$，宽度为$c$的点。公式中$N$代表channel数，$a$为输出，$\frac{n}{2}$表示深度半径，$k$为偏置，$\alpha$和$\beta$为自定义参数。该公式可以理解为对某点按通道邻域进行归一化。当这个通道邻域为这个通道时，即为pixel-wise normalization。公式如下：<br>$$b_{x,y} = \frac{a_{x,y}}{\sqrt{\frac{1}{N}\sum_{j=0}^{N-1}{(a_{x,y}^j)^2 + \epsilon}}}$$<br>其中$\epsilon = 10^{-8}$，$N$是feature map的个数，$a_{x,y}$和$b_{x,y}$分别是$pixel(x,y)$原始向量和归一化向量。文章指出这种约束并没有损害生成器，并且在大多数数据集上它也没有太大地改变效果。但这种归一化可以非常有效地防止信号幅度的上升。</p>
<h2 id="minibatch-standard-deviation"><a href="#minibatch-standard-deviation" class="headerlink" title="minibatch standard deviation"></a>minibatch standard deviation</h2><p>在Improved GAN中作者指出，出现mode collapse后，没有任何信息能引导网络走出这一困境。生成器的每个minibatch输出都应该具有足够的分辩能力，即每个minibatch不应该太相似。惩罚minibatch的相似性能够在mode collapse发生时，产生足够的梯度信息，引导它走出。具体做法如下。<br>假设样本$x_i$在D网络中某一层的特征向量为$f(x_i) \in R^A$，然后将$f(x_i)$乘以一个张量$T \in R^{A \times B \times C}$得到张量$M_i \in R^B \times C$。基于不同的样本生成的矩阵$M_i,i=1,2,…,n$的行之间计算$L_1$距离，得到$c_b(x_i,x_j) = e^{-||M_{ib}-M_{jb}|| _{L1}} \in R$，然后将所有的$c_b(x_i,x_j)$相加得到$o(x_i)_b$，最后将$B$个$o(x_i)_b$并起来得到一个大小为$B$的向量$o(x_i)$。最后，将$o(x_i)$和$f(x_i)$合并成一个向量作为D网络下一层的输入。如图1所示。<br>$$o(x_i)_b = \sum_{j=1}^{n}{c_b(x_i,x_j)} \in \mathbb{R}$$<br>$$o(x_i) = [o(x_i)_1, o(x_i)_2, …, o(x_i)_B] \in \mathbb{B}$$<br>$$o(X) \in \mathbb{R}^{n \times B}$$<br><img alt="图1" data-src="/img/pggan3.jpg" class="lazyload"><br>PGGAN中提出的minibatch standard deviation也是基于这种思路。看下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">minibatch_std_concat_layer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, averaging=<span class="string">'all'</span>)</span>:</span></span><br><span class="line">        super(minibatch_std_concat_layer, self).__init__()</span><br><span class="line">        self.averaging = averaging.lower()</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'group'</span> <span class="keyword">in</span> self.averaging:</span><br><span class="line">            self.n = int(self.averaging[<span class="number">5</span>:])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">assert</span> self.averaging <span class="keyword">in</span> [<span class="string">'all'</span>], <span class="string">'Invalid averaging mode'</span>%self.averaging</span><br><span class="line">        self.adjusted_std = <span class="keyword">lambda</span> x, **kwargs: torch.sqrt(torch.mean((x - torch.mean(x, **kwargs)) ** <span class="number">2</span>, **kwargs) + <span class="number">1e-8</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span>   <span class="comment"># [32,512,4,4]</span></span><br><span class="line">        shape = list(x.size())</span><br><span class="line">        target_shape = copy.deepcopy(shape)</span><br><span class="line">        vals = self.adjusted_std(x, dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)    <span class="comment"># [1,512,4,4]</span></span><br><span class="line">        <span class="keyword">if</span> self.averaging == <span class="string">'all'</span>:</span><br><span class="line">            target_shape[<span class="number">1</span>] = <span class="number">1</span>     </span><br><span class="line">            vals = torch.mean(vals, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)    <span class="comment"># [1,1,4,4]</span></span><br><span class="line">        <span class="keyword">else</span>:                                                           <span class="comment"># self.averaging == 'group'</span></span><br><span class="line">            target_shape[<span class="number">1</span>] = self.n</span><br><span class="line">            vals = vals.view(self.n, self.shape[<span class="number">1</span>]/self.n, self.shape[<span class="number">2</span>], self.shape[<span class="number">3</span>])</span><br><span class="line">            vals = mean(vals, axis=<span class="number">0</span>, keepdim=<span class="literal">True</span>).view(<span class="number">1</span>, self.n, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        vals = vals.expand(*target_shape)   <span class="comment"># target_shape:[32,1,4,4]-&gt; vals shape:[32,1,4,4]</span></span><br><span class="line">        <span class="keyword">return</span> torch.cat([x, vals], <span class="number">1</span>)  <span class="comment"># [32,513,4,4]</span></span><br></pre></td></tr></table></figure>
<p>输入x为feature map。其中adjusted_std函数用来根据指定维度计算标准差。在调用时，首先在batch方向上计算标准差vals,然后在channel方向上计算这些标准差的均值。将最终的均值concat在feature map之后。</p>
<h2 id="有针对性地给样本加噪声"><a href="#有针对性地给样本加噪声" class="headerlink" title="有针对性地给样本加噪声"></a>有针对性地给样本加噪声</h2><p>在文章Towards Principled Methods for Training Generative Adversarial Networks中，作者分析了GAN损失函数存在的问题，并提出了两种解决方法。其中一种是对两个分布加噪声，使其能重叠，以此来缓解mode collapse。当生成样本在判别器中的输出接近1时，此时的loss会接近常数，梯度接近消失。不能再来引导生成器。因此，可以用添加噪声的方式来避免这种问题。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_noise</span><span class="params">(self, x)</span>:</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> support more method of adding noise.</span></span><br><span class="line">    <span class="keyword">if</span> self.flag_add_noise==<span class="literal">False</span>:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> hasattr(self, <span class="string">'_d_'</span>):    <span class="comment"># 有_d_属性，d*0.9 + fx_tilde*0.1，fx_tilde为生成样本经过判别器后的结果</span></span><br><span class="line">        self._d_ = self._d_ * <span class="number">0.9</span> + torch.mean(self.fx_tilde).item() * <span class="number">0.1</span></span><br><span class="line">    <span class="keyword">else</span>:        <span class="comment"># 给输入向量添加_d_属性，并赋值为0</span></span><br><span class="line">        self._d_ = <span class="number">0.0</span></span><br><span class="line">    strength = <span class="number">0.2</span> * max(<span class="number">0</span>, self._d_ - <span class="number">0.5</span>)**<span class="number">2</span>      </span><br><span class="line">    z = np.random.randn(*x.size()).astype(np.float32) * strength</span><br><span class="line">    z = Variable(torch.from_numpy(z)).cuda() <span class="keyword">if</span> self.use_cuda <span class="keyword">else</span> Variable(torch.from_numpy(z))</span><br><span class="line">    <span class="keyword">return</span> x + z</span><br></pre></td></tr></table></figure>
<p>其中strength用来控制噪声大小，其值与变量<em>d</em>有关。而<em>d</em>的值与真实样本在判别器的输出有关。也就是说 ，判别器输出越大，所加的噪声越大。而当判别器输出小于0.5时，不添加噪声。原因是网络收敛时，判别器对于样本的判别概率应该是0.5，那么当输出小于0.5时表明网络的分辨能力较弱。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">wwq</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="/wwq66.github.io/2019/11/26/pytorchRecord/">wwq66.github.io/2019/11/26/pytorchRecord/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="wwq66.github.io">HapiBlog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/PyTorch/">PyTorch    </a><a class="post-meta__tags" href="/tags/GANs/">GANs    </a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2019/11/13/HbTRirt8nyfpNWF.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button"><i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.jpg"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg"><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2019/12/05/ganloss/"><img class="prev_cover lazyload" data-src="https://i.loli.net/2019/11/13/HbTRirt8nyfpNWF.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>ganloss</span></div></a></div><div class="next-post pull_right"><a href="/2019/11/25/pggan/"><img class="next_cover lazyload" data-src="https://i.loli.net/2019/11/13/MWJC6vcXqKHgaiY.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>【PGGAN】PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/12/05/ganloss/" title="ganloss"><img class="relatedPosts_cover lazyload"data-src="https://i.loli.net/2019/11/13/HbTRirt8nyfpNWF.jpg"><div class="relatedPosts_title">ganloss</div></a></div><div class="relatedPosts_item"><a href="/2019/11/25/pggan/" title="【PGGAN】PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION"><img class="relatedPosts_cover lazyload"data-src="https://i.loli.net/2019/11/13/MWJC6vcXqKHgaiY.png"><div class="relatedPosts_title">【PGGAN】PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION</div></a></div></div><div class="clear_both"></div></div></div></div><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 By wwq</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="/js/third-party/ClickShowText.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>